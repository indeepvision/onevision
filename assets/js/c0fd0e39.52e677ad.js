"use strict";(self.webpackChunk_indeepvision_onevision_docs=self.webpackChunk_indeepvision_onevision_docs||[]).push([[6161],{2247:(e,t,a)=>{a.d(t,{xA:()=>m,yg:()=>p});var i=a(4041);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,i)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,i,r=function(e,t){if(null==e)return{};var a,i,r={},n=Object.keys(e);for(i=0;i<n.length;i++)a=n[i],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(i=0;i<n.length;i++)a=n[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=i.createContext({}),c=function(e){var t=i.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=c(e.components);return i.createElement(s.Provider,{value:t},e.children)},u="mdxType",f={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},g=i.forwardRef((function(e,t){var a=e.components,r=e.mdxType,n=e.originalType,s=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),u=c(a),g=r,p=u["".concat(s,".").concat(g)]||u[g]||f[g]||n;return a?i.createElement(p,o(o({ref:t},m),{},{components:a})):i.createElement(p,o({ref:t},m))}));function p(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var n=a.length,o=new Array(n);o[0]=g;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:r,o[1]=l;for(var c=2;c<n;c++)o[c]=a[c];return i.createElement.apply(null,o)}return i.createElement.apply(null,a)}g.displayName="MDXCreateElement"},5567:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>f,frontMatter:()=>n,metadata:()=>l,toc:()=>c});var i=a(9575),r=(a(4041),a(2247));const n={sidebar_position:4},o="Camera Configuration",l={unversionedId:"software-guide/cameras/camera-configuration",id:"software-guide/cameras/camera-configuration",title:"Camera Configuration",description:"The basic configuration sub-menu is used to configure the parameters of the camera controller itself, not the internal features of the camera as a device. In summary, here you can configure how OneVision and the camera will work together.",source:"@site/docs/software-guide/cameras/camera-configuration.md",sourceDirName:"software-guide/cameras",slug:"/software-guide/cameras/camera-configuration",permalink:"/onevision/docs/software-guide/cameras/camera-configuration",draft:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"softwareGuide",previous:{title:"Understanding the Image Buffer",permalink:"/onevision/docs/software-guide/cameras/image-buffer"},next:{title:"Features List",permalink:"/onevision/docs/software-guide/cameras/features-list"}},s={},c=[{value:"Friendly name",id:"friendly-name",level:3},{value:"Enable/disable camera",id:"enabledisable-camera",level:3},{value:"Critical",id:"critical",level:3},{value:"Pixel format",id:"pixel-format",level:3},{value:"Rotation",id:"rotation",level:3},{value:"Flip",id:"flip",level:3},{value:"Image buffer size",id:"image-buffer-size",level:3},{value:"Log level",id:"log-level",level:3}],m={toc:c},u="wrapper";function f(e){let{components:t,...n}=e;return(0,r.yg)(u,(0,i.A)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"camera-configuration"},"Camera Configuration"),(0,r.yg)("p",null,"The basic configuration sub-menu is used to configure the parameters of the camera controller itself, not the internal features of the camera as a device. In summary, here you can configure how OneVision and the camera will work together."),(0,r.yg)("p",null,(0,r.yg)("img",{alt:"&quot;Basic configuration&quot;",src:a(8105).A,width:"1152",height:"690"})),(0,r.yg)("h3",{id:"friendly-name"},"Friendly name"),(0,r.yg)("p",null,"The friendly name is the unique name of the camera controller that will be used throughout the proejct. It must be unique, but can be changed at any time."),(0,r.yg)("h3",{id:"enabledisable-camera"},"Enable/disable camera"),(0,r.yg)("p",null,"This option is used to enable or disable the camera controller. If the controller is disabled, it will not be used in the project and will not connect to the camera device."),(0,r.yg)("h3",{id:"critical"},"Critical"),(0,r.yg)("p",null,"This option is used to mark the camera controller as critical. If the controller is critical, the software will consider an error if the camera is not connected. For example, runtime execution will stop if connection with the camera device is lost."),(0,r.yg)("p",null,'When a critical camera is not connected, the camera tab will display a "red" icon next to the camera name. If it is not connected but it is not critical, the icon will be "orange" to indicate a warning.'),(0,r.yg)("h3",{id:"pixel-format"},"Pixel format"),(0,r.yg)("p",null,"The pixel format configured here will determine the format of the image that is received from the camera. This might not be the pixel format that camera device delivers to the computer, since OneVision will convert the image to the configured format if necessary."),(0,r.yg)("p",null,"It might be necessary for example to convert an image that is streamed from the camera in ",(0,r.yg)("strong",{parentName:"p"},"Bayer")," format to ",(0,r.yg)("strong",{parentName:"p"},"BGR")," format, so that it can be used by the AI models."),(0,r.yg)("p",null,"Only 3 possible formats are allowed to stream from the camera:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Mono8: Monochrome 8-bit"),(0,r.yg)("li",{parentName:"ul"},"Mono16: Monochrome 16-bit"),(0,r.yg)("li",{parentName:"ul"},"BGR8: Blue-Green-Red 8-bit")),(0,r.yg)("p",null,"Consult the supported image formats by images in the ",(0,r.yg)("a",{parentName:"p",href:"../../getting-started/the-basics/specifications"},(0,r.yg)("strong",{parentName:"a"},"Specifications"))," section."),(0,r.yg)("admonition",{type:"tip"},(0,r.yg)("p",{parentName:"admonition"},"Like OpenCV, OneVision uses the ",(0,r.yg)("strong",{parentName:"p"},"BGR8")," format instead of the ",(0,r.yg)("strong",{parentName:"p"},"RGB8")," format. This means that the first pixel in the image is the blue component, the second pixel is the green component and the third pixel is the red component.")),(0,r.yg)("h3",{id:"rotation"},"Rotation"),(0,r.yg)("p",null,"The rotation of the image can be configured here. The rotation is applied to the image after it is received from the camera, by software. The user will receive the image already rotated."),(0,r.yg)("p",null,"Rotation can be configured with the following values:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"0: The image is not rotated (default)."),(0,r.yg)("li",{parentName:"ul"},"90: The image is rotated 90 degrees clockwise."),(0,r.yg)("li",{parentName:"ul"},"180: The image is rotated 180 degrees clockwise."),(0,r.yg)("li",{parentName:"ul"},"270: The image is rotated 270 degrees clockwise.")),(0,r.yg)("admonition",{type:"tip"},(0,r.yg)("p",{parentName:"admonition"},"If the camera's internal features allow rotation and flip, it might be more efficient to configure the rotation directly in the camera device instead of configuring it by software here in OneVision.")),(0,r.yg)("h3",{id:"flip"},"Flip"),(0,r.yg)("p",null,"The flip of the image can be configured here. The flip is applied to the image after it is received from the camera, by software. The user will receive the image already flipped."),(0,r.yg)("p",null,"Flip can be configured with the following values:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"None: The image is not flipped (default)."),(0,r.yg)("li",{parentName:"ul"},"Horizontal: The image is flipped horizontally."),(0,r.yg)("li",{parentName:"ul"},"Vertical: The image is flipped vertically."),(0,r.yg)("li",{parentName:"ul"},"Both: The image is flipped horizontally and vertically.")),(0,r.yg)("h3",{id:"image-buffer-size"},"Image buffer size"),(0,r.yg)("p",null,"The image buffer is a ring buffer, which means that it has a fixed size and it is filled with the images that are received from the camera. Once the buffer is full, the oldest images are discarded to make room for the new images."),(0,r.yg)("p",null,"For many vision applications the image buffer will have no importance, it can be left with the default value."),(0,r.yg)("p",null,"However, for some applications it might be important to configure the size of the buffer. For example, if the camera and processing work in parallel, not at the same speed, it might be necessary to increase the size of the buffer to avoid losing images if processing is slower than acquisition."),(0,r.yg)("h3",{id:"log-level"},"Log level"),(0,r.yg)("p",null,"This option is used to configure the level of detail of the logs that are generated by the camera controller. This option is mainly intended for developers. The possible values are:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"DEBUG: The most detailed level of logs."),(0,r.yg)("li",{parentName:"ul"},"INFO: A normal level of logs (default)."),(0,r.yg)("li",{parentName:"ul"},"WARNING: Only warnings and errors are logged."),(0,r.yg)("li",{parentName:"ul"},"ERROR: Only errors are logged.")))}f.isMDXComponent=!0},8105:(e,t,a)=>{a.d(t,{A:()=>i});const i=a.p+"assets/images/camera_basic_configuration_60-a155417e19af0e73e03e214d83404825.PNG"}}]);